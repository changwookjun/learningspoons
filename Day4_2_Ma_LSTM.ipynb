{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Day4_2_Ma_LSTM.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bG4_-K7Z6aub",
        "colab_type": "text"
      },
      "source": [
        "# Ma LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ixJi5iWk6VzH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2ozbQUx6crE",
        "colab_type": "code",
        "outputId": "66c0272e-c0b3-425e-e555-7ecac6460219",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q1c3mIopN57-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DATA_IN_PATH = './data_in/'\n",
        "DATA_OUT_PATH = './data_out/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ng1WcFqu2Tr",
        "colab_type": "code",
        "outputId": "09231d98-4d80-46bc-d978-22d106492cce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        }
      },
      "source": [
        "!ls -al"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 40\n",
            "drwxr-xr-x 1 root root 4096 Jun 21 02:43 .\n",
            "drwxr-xr-x 1 root root 4096 Jun 21 02:42 ..\n",
            "-rw-r--r-- 1 root root 2487 Jun 21 02:43 adc.json\n",
            "drwxr-xr-x 1 root root 4096 Jun 21 02:43 .config\n",
            "drwxr-xr-x 2 root root 4096 Jun 21 02:48 data_in\n",
            "drwxr-xr-x 3 root root 4096 Jun 21 03:00 data_out\n",
            "drwx------ 3 root root 4096 Jun 21 02:43 gdrive\n",
            "drwxr-xr-x 1 root root 4096 Jun 18 16:14 sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XqBTKs0MN9s2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TRAIN_Q1_DATA_FILE = 'train_q1.npy'\n",
        "TRAIN_Q2_DATA_FILE = 'train_q2.npy'\n",
        "TRAIN_LABEL_DATA_FILE = 'train_label.npy'\n",
        "NB_WORDS_DATA_FILE = 'data_configs.json'\n",
        "\n",
        "## 학습에 필요한 파라메터들에 대해서 지정하는 부분이다.\n",
        "\n",
        "BATCH_SIZE = 4096\n",
        "EPOCH = 2\n",
        "HIDDEN = 64\n",
        "\n",
        "DROPOUT_RATIO = 0.3\n",
        "\n",
        "TEST_SPLIT = 0.1\n",
        "RNG_SEED = 13371447\n",
        "EMBEDDING_DIM = 128\n",
        "MAX_SEQ_LEN = 31"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SMqbutxbOBjN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## 데이터를 불러오는 부분이다. 효과적인 데이터 불러오기를 위해, 미리 넘파이 형태로 저장시킨 데이터를 로드한다.\n",
        "\n",
        "q1_data = np.load(open(DATA_IN_PATH + TRAIN_Q1_DATA_FILE, 'rb'))\n",
        "q2_data = np.load(open(DATA_IN_PATH + TRAIN_Q2_DATA_FILE, 'rb'))\n",
        "labels = np.load(open(DATA_IN_PATH + TRAIN_LABEL_DATA_FILE, 'rb'))\n",
        "prepro_configs = None\n",
        "\n",
        "with open(DATA_IN_PATH + NB_WORDS_DATA_FILE, 'r') as f:\n",
        "    prepro_configs = json.load(f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kgEEPYtIOD5E",
        "colab_type": "code",
        "outputId": "4e695fa2-61d7-4e3a-d7f1-7385aec34552",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "VOCAB_SIZE = prepro_configs['vocab_size']\n",
        "VOCAB_SIZE"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "76558"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TyIcRnSAwA75",
        "colab_type": "text"
      },
      "source": [
        "### Split train and test dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nrdXZS1XOFm8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "q1_data_len = np.array([min(len(x), MAX_SEQ_LEN) for x in q1_data])\n",
        "q2_data_len = np.array([min(len(x), MAX_SEQ_LEN) for x in q2_data])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3840A8nNOPUl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## 데이터를 나누어 저장하자. sklearn의 train_test_split을 사용하면 유용하다. 하지만, 쿼라 데이터의 경우는\n",
        "## 입력이 1개가 아니라 2개이다. 따라서, np.stack을 사용하여 두개를 하나로 쌓은다음 활용하여 분류한다.\n",
        "\n",
        "X = np.stack((q1_data, q2_data), axis=1)\n",
        "y = labels\n",
        "train_X, test_X, train_y, test_y = train_test_split(X, y, test_size=TEST_SPLIT, random_state=RNG_SEED)\n",
        "\n",
        "train_Q1 = train_X[:,0]\n",
        "train_Q2 = train_X[:,1]\n",
        "test_Q1 = test_X[:,0]\n",
        "test_Q2 = test_X[:,1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Orbt7YELOQ91",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def rearrange(base, hypothesis, labels):\n",
        "    features = {\"base\": base, \"hypothesis\": hypothesis}\n",
        "    return features, labels\n",
        "\n",
        "def train_input_fn():\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((train_Q1, train_Q2, train_y))\n",
        "    dataset = dataset.shuffle(buffer_size=len(train_Q1))\n",
        "    dataset = dataset.batch(BATCH_SIZE) #4096\n",
        "    dataset = dataset.map(rearrange)\n",
        "    dataset = dataset.repeat(EPOCH) # 2\n",
        "    iterator = dataset.make_one_shot_iterator()\n",
        "    \n",
        "    return iterator.get_next()\n",
        "\n",
        "def eval_input_fn():\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((test_Q1, test_Q2, test_y))\n",
        "    dataset = dataset.batch(BATCH_SIZE) #4096\n",
        "    dataset = dataset.map(rearrange)\n",
        "    iterator = dataset.make_one_shot_iterator()\n",
        "    \n",
        "    return iterator.get_next()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nvXOXlSywPR2",
        "colab_type": "text"
      },
      "source": [
        "### Model Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SROF7Q--JsQW",
        "colab": {}
      },
      "source": [
        "def Malstm(features, labels, mode):\n",
        "        \n",
        "    TRAIN = mode == tf.estimator.ModeKeys.TRAIN\n",
        "    EVAL = mode == tf.estimator.ModeKeys.EVAL\n",
        "    PREDICT = mode == tf.estimator.ModeKeys.PREDICT\n",
        "    # VOCAB_SIZE : 76558   EMBEDDING_DIM : 128       \n",
        "    embedding = tf.keras.layers.Embedding(VOCAB_SIZE, EMBEDDING_DIM) \n",
        "    \n",
        "    base_embedded_matrix = embedding(features['base']) # (?, 31, 128)\n",
        "    \n",
        "    hypothesis_embedded_matrix = embedding(features['hypothesis']) # (?, 31, 128)\n",
        "    \n",
        "    q_lstm_cell = tf.nn.rnn_cell.BasicLSTMCell(num_units = HIDDEN, activation = tf.nn.tanh , state_is_tuple=False)\n",
        "    \n",
        "    q, q_output_states = tf.nn.dynamic_rnn(cell = q_lstm_cell, #  LSTMStateTuple(c(?, 64), h(?, 64))\n",
        "                                           inputs = base_embedded_matrix, # shape=(?, 128)\n",
        "                                           dtype = tf.float32,\n",
        "                                           scope='query')       \n",
        "    \n",
        "    s_lstm_cell = tf.nn.rnn_cell.BasicLSTMCell(num_units = HIDDEN, activation = tf.nn.tanh, state_is_tuple=False) \n",
        "\n",
        "    s, s_output_states = tf.nn.dynamic_rnn(cell = s_lstm_cell, \n",
        "                                           inputs = base_embedded_matrix, \n",
        "                                           dtype = tf.float32,\n",
        "                                           scope='sim_query')     \n",
        "\n",
        "    with tf.variable_scope('output_layer'):\n",
        "        logit_layer = tf.exp(-tf.reduce_sum(tf.abs(q_output_states - s_output_states), axis=1, keepdims=True)) # (?, 1)\n",
        "        logit_layer = tf.squeeze(logit_layer, axis=-1) #(?,)\n",
        "      \n",
        "    if PREDICT:\n",
        "        return tf.estimator.EstimatorSpec(\n",
        "                  mode=mode,\n",
        "                  predictions={\n",
        "                      'is_duplicate':logit_layer\n",
        "                  })\n",
        "    \n",
        "    #prediction 진행 시, None\n",
        "    if labels is not None:\n",
        "        labels = tf.to_float(labels)\n",
        "    \n",
        "    loss = tf.losses.mean_squared_error(labels=labels, predictions=logit_layer)\n",
        "\n",
        "    if EVAL:\n",
        "        accuracy = tf.metrics.accuracy(labels, tf.round(logit_layer))\n",
        "        eval_metric_ops = {'acc': accuracy}\n",
        "        return tf.estimator.EstimatorSpec(\n",
        "                  mode=mode,\n",
        "                  eval_metric_ops= eval_metric_ops,\n",
        "                  loss=loss)\n",
        "\n",
        "    elif TRAIN:\n",
        "\n",
        "        global_step = tf.train.get_global_step()\n",
        "        train_op = tf.train.AdamOptimizer(1e-3).minimize(loss, global_step)\n",
        "\n",
        "        return tf.estimator.EstimatorSpec(\n",
        "                  mode=mode,\n",
        "                  train_op=train_op,\n",
        "                  loss=loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jnCkOq-BKi9Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -rf /checkpoint/malstm/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jBYLAo6dQIWF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_dir = os.path.join(os.getcwd(), DATA_OUT_PATH + \"/checkpoint/malstm/\")\n",
        "os.makedirs(model_dir, exist_ok=True)\n",
        "\n",
        "config_tf = tf.estimator.RunConfig()\n",
        "\n",
        "lstm_est = tf.estimator.Estimator(Malstm, model_dir=model_dir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NYXw_VqWeIW8",
        "colab_type": "text"
      },
      "source": [
        "### 아래 루틴 엄청 오래 걸림"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_RfzgupQMSl",
        "colab_type": "code",
        "outputId": "c7a5a8f6-5893-47f3-a6a3-27bff4a67505",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        }
      },
      "source": [
        "lstm_est.train(train_input_fn)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0621 03:54:24.027960 140177333548928 rnn_cell_impl.py:697] <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x7f7d4881c518>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "embedding:  <tensorflow.python.keras.layers.embeddings.Embedding object at 0x7f7d488615c0>\n",
            "base_embedded_matrix:  Tensor(\"embedding/embedding_lookup/Identity_1:0\", shape=(?, 31, 128), dtype=float32)\n",
            "hypothesis_embedded_matrix:  Tensor(\"embedding_1/embedding_lookup/Identity_1:0\", shape=(?, 31, 128), dtype=float32)\n",
            "q_lstm_cell:  <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x7f7d4881c518>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0621 03:54:24.393178 140177333548928 rnn_cell_impl.py:697] <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x7f7d488297f0>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "q:  Tensor(\"query/transpose_1:0\", shape=(?, 31, 64), dtype=float32)\n",
            "q_output_states:  Tensor(\"query/while/Exit_3:0\", shape=(?, 128), dtype=float32)\n",
            "s_lstm_cell:  <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x7f7d488297f0>\n",
            "s:  Tensor(\"sim_query/transpose_1:0\", shape=(?, 31, 64), dtype=float32)\n",
            "s_output_states:  Tensor(\"sim_query/while/Exit_3:0\", shape=(?, 128), dtype=float32)\n",
            "logit_layer:  Tensor(\"output_layer/Exp:0\", shape=(?, 1), dtype=float32)\n",
            "logit_layer:  Tensor(\"output_layer/Squeeze:0\", shape=(?,), dtype=float32)\n",
            "loss:  Tensor(\"mean_squared_error/value:0\", shape=(), dtype=float32)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0621 03:54:25.687252 140177333548928 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1066: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file utilities to get mtimes.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow_estimator.python.estimator.estimator.Estimator at 0x7f7d4a0bf080>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lf5pVJ2mQOH4",
        "colab_type": "code",
        "outputId": "4d095ee0-99c4-4cf2-be98-9710ec0936fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "lstm_est.evaluate(eval_input_fn)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0621 04:02:13.202722 140177333548928 rnn_cell_impl.py:697] <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x7f7d4bd9dd68>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "embedding:  <tensorflow.python.keras.layers.embeddings.Embedding object at 0x7f7d51a2e278>\n",
            "base_embedded_matrix:  Tensor(\"embedding/embedding_lookup/Identity_1:0\", shape=(?, 31, 128), dtype=float32)\n",
            "hypothesis_embedded_matrix:  Tensor(\"embedding_1/embedding_lookup/Identity_1:0\", shape=(?, 31, 128), dtype=float32)\n",
            "q_lstm_cell:  <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x7f7d4bd9dd68>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0621 04:02:13.590102 140177333548928 rnn_cell_impl.py:697] <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x7f7d4bd96978>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "q:  Tensor(\"query/transpose_1:0\", shape=(?, 31, 64), dtype=float32)\n",
            "q_output_states:  Tensor(\"query/while/Exit_3:0\", shape=(?, 128), dtype=float32)\n",
            "s_lstm_cell:  <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x7f7d4bd96978>\n",
            "s:  Tensor(\"sim_query/transpose_1:0\", shape=(?, 31, 64), dtype=float32)\n",
            "s_output_states:  Tensor(\"sim_query/while/Exit_3:0\", shape=(?, 128), dtype=float32)\n",
            "logit_layer:  Tensor(\"output_layer/Exp:0\", shape=(?, 1), dtype=float32)\n",
            "logit_layer:  Tensor(\"output_layer/Squeeze:0\", shape=(?,), dtype=float32)\n",
            "loss:  Tensor(\"mean_squared_error/value:0\", shape=(), dtype=float32)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'acc': 0.72096604, 'global_step': 396, 'loss': 0.18823466}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLab41oLQSQV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TEST_Q1_DATA_FILE = 'test_q1.npy'\n",
        "TEST_Q2_DATA_FILE = 'test_q2.npy'\n",
        "TEST_ID_DATA_FILE = 'test_id.npy'\n",
        "\n",
        "test_q1_data = np.load(open(DATA_IN_PATH + TEST_Q1_DATA_FILE, 'rb'))\n",
        "test_q2_data = np.load(open(DATA_IN_PATH + TEST_Q2_DATA_FILE, 'rb'))\n",
        "test_id_data = np.load(open(DATA_IN_PATH + TEST_ID_DATA_FILE, 'rb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ky3XTfebQWeR",
        "colab_type": "code",
        "outputId": "9bcc54b0-6ccb-45b5-8440-2e4c9cff3169",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        }
      },
      "source": [
        "predict_input_fn = tf.estimator.inputs.numpy_input_fn(x={\"base\":test_q1_data, \n",
        "                                                         \"hypothesis\":test_q2_data}, \n",
        "                                                      shuffle=False)\n",
        "\n",
        "predictions = np.array([p['is_duplicate'] for p in lstm_est.predict(input_fn=predict_input_fn)])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0621 04:11:10.219111 140177333548928 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/inputs/queues/feeding_queue_runner.py:62: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "To construct input pipelines, use the `tf.data` module.\n",
            "W0621 04:11:10.222349 140177333548928 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/inputs/queues/feeding_functions.py:500: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "To construct input pipelines, use the `tf.data` module.\n",
            "W0621 04:11:10.259637 140177333548928 rnn_cell_impl.py:697] <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x7f7d50c74e48>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n",
            "W0621 04:11:10.392072 140177333548928 rnn_cell_impl.py:697] <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x7f7d50c74e10>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "embedding:  <tensorflow.python.keras.layers.embeddings.Embedding object at 0x7f7d523a4668>\n",
            "base_embedded_matrix:  Tensor(\"embedding/embedding_lookup/Identity_1:0\", shape=(?, 31, 128), dtype=float32)\n",
            "hypothesis_embedded_matrix:  Tensor(\"embedding_1/embedding_lookup/Identity_1:0\", shape=(?, 31, 128), dtype=float32)\n",
            "q_lstm_cell:  <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x7f7d50c74e48>\n",
            "q:  Tensor(\"query/transpose_1:0\", shape=(?, 31, 64), dtype=float32)\n",
            "q_output_states:  Tensor(\"query/while/Exit_3:0\", shape=(?, 128), dtype=float32)\n",
            "s_lstm_cell:  <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x7f7d50c74e10>\n",
            "s:  Tensor(\"sim_query/transpose_1:0\", shape=(?, 31, 64), dtype=float32)\n",
            "s_output_states:  Tensor(\"sim_query/while/Exit_3:0\", shape=(?, 128), dtype=float32)\n",
            "logit_layer:  Tensor(\"output_layer/Exp:0\", shape=(?, 1), dtype=float32)\n",
            "logit_layer:  Tensor(\"output_layer/Squeeze:0\", shape=(?,), dtype=float32)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0621 04:11:10.743502 140177333548928 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/monitored_session.py:875: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "To construct input pipelines, use the `tf.data` module.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mU3yVFv2Qbs2",
        "colab_type": "code",
        "outputId": "8035354d-015e-4843-dda3-6a49e7644d01",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(len(predictions)) #2345796\n",
        "\n",
        "output = pd.DataFrame( data={\"test_id\":test_id_data, \"is_duplicate\": list(predictions)} )\n",
        "output.to_csv( \"/content/gdrive/My Drive/Colab Notebooks/Data/rnn_predict.csv\", index=False, quoting=3 )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2345796\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TqGo5SpXBSrX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}